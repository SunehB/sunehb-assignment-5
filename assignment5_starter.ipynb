{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "7BGsoRonpWi_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "O2CydyFgpWjA"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = np.array(X, dtype=np.float64)\n",
        "        self.y_train = np.array(y, dtype=np.float64)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            np.array(x, dtype=np.float64)\n",
        "            distances = self.compute_distance(x, self.X_train)\n",
        "            nn_indices = np.argsort(distances)[:self.k]\n",
        "            nn_labels = self.y_train[nn_indices]\n",
        "            # Probability is the mean of the neighbor labels\n",
        "            prob = np.mean(nn_labels)\n",
        "            predictions.append(prob)\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        # TODO: Implement distance computation based on self.distance_metric\n",
        "        # # Hint: Use numpy operations for efficient computation\n",
        "        # print(\"Type of X1:\", type(X1))\n",
        "        # print(\"Type of X2:\", type(X2))\n",
        "        # print(\"Shape of X1:\", np.shape(X1))\n",
        "        # print(\"Shape of X2:\", np.shape(X2))\n",
        "        # print(\"X1 dtype:\", X1.dtype)\n",
        "        # print(\"X2 dtype:\", X2.dtype)\n",
        "        # print(\"First element of X1:\", X1[0], \"Type:\", type(X1[0]))\n",
        "        # print(\"First row of X2:\", X2[0], \"Types:\", [type(x) for x in X2[0]])\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            distances = np.sqrt(np.sum((X2 - X1) ** 2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            distances = np.sum(np.abs(X2 - X1), axis=1)\n",
        "        elif self.distance_metric == 'minkowski':\n",
        "            distances = np.sum(np.abs(X1 - X2) ** 1.5, axis=1) ** (1/1.5)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "        return distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "wEndROAVpWjB"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(train_path, test_path):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    # Load the datasets\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Combine train and test data for consistent preprocessing\n",
        "    train_data['is_train'] = 1\n",
        "    test_data['is_train'] = 0\n",
        "    data = pd.concat([train_data, test_data], sort=False).reset_index(drop=True)\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    data.drop(['CustomerId', 'Surname'], axis=1, inplace=True)\n",
        "\n",
        "    # Handle missing values in categorical columns\n",
        "    for col in ['Gender', 'Geography']:\n",
        "        data[col].fillna(data[col].mode()[0], inplace=True)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    data['Gender'] = data['Gender'].map({'Female': 0, 'Male': 1})\n",
        "\n",
        "    # One-hot encode 'Geography'\n",
        "    data = pd.get_dummies(data, columns=['Geography'], drop_first=True)\n",
        "\n",
        "    # Convert any boolean columns to integers\n",
        "    bool_cols = data.select_dtypes(include=['bool']).columns.tolist()\n",
        "    if bool_cols:\n",
        "        data[bool_cols] = data[bool_cols].astype(int)\n",
        "\n",
        "    # Convert all columns to float64\n",
        "    data = data.astype('float64')\n",
        "\n",
        "    # Handle any remaining missing values after conversion\n",
        "    data.fillna(0, inplace=True)\n",
        "\n",
        "    # Feature scaling (standardization)\n",
        "    numerical_cols = data.columns.drop(['Exited', 'is_train'])\n",
        "    for feature in numerical_cols:\n",
        "        mean = data[feature].mean()\n",
        "        std = data[feature].std()\n",
        "        if std != 0:\n",
        "            data[feature] = (data[feature] - mean) / std\n",
        "        else:\n",
        "            data[feature] = 0.0\n",
        "\n",
        "    # Split the data back into train and test sets\n",
        "    train_data_processed = data[data['is_train'] == 1].drop('is_train', axis=1)\n",
        "    test_data_processed = data[data['is_train'] == 0].drop(['is_train', 'Exited'], axis=1)\n",
        "\n",
        "    # Extract features and target variable\n",
        "    X_train = train_data_processed.drop('Exited', axis=1).values\n",
        "    y_train = train_data_processed['Exited'].values\n",
        "    X_test = test_data_processed.values\n",
        "\n",
        "    return X_train, y_train, X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_k_fold_split(X, y, n_splits):\n",
        "    \"\"\"\n",
        "    Generate indices to split data into training and test set while preserving the percentage of samples for each class.\n",
        "    \"\"\"\n",
        "    indices = np.arange(len(y))\n",
        "    unique_classes, y_indices = np.unique(y, return_inverse=True)\n",
        "    class_counts = np.bincount(y_indices)\n",
        "    fold_counts = (class_counts * n_splits) // len(y)\n",
        "    folds = [[] for _ in range(n_splits)]\n",
        "\n",
        "    for cls in unique_classes:\n",
        "        cls_indices = indices[y == cls]\n",
        "        np.random.shuffle(cls_indices)\n",
        "        cls_folds = np.array_split(cls_indices, n_splits)\n",
        "        for i in range(n_splits):\n",
        "            folds[i].extend(cls_folds[i])\n",
        "    return folds\n"
      ],
      "metadata": {
        "id": "GqhlmVIgtwyX"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_roc_auc(y_true, y_scores):\n",
        "    \"\"\"\n",
        "    Compute ROC AUC score from true labels and predicted scores.\n",
        "    \"\"\"\n",
        "    # Sort scores and corresponding true labels\n",
        "    y_true = np.array(y_true)\n",
        "    y_scores = np.array(y_scores)\n",
        "\n",
        "    # Sort scores and corresponding true labels\n",
        "    desc_score_indices = np.argsort(y_scores)[::-1]\n",
        "    y_true = y_true[desc_score_indices]\n",
        "    y_scores = y_scores[desc_score_indices]\n",
        "\n",
        "    # Compute True Positive Rate (TPR) and False Positive Rate (FPR)\n",
        "    thresholds = np.unique(y_scores)\n",
        "    tpr = []\n",
        "    fpr = []\n",
        "    P = np.sum(y_true)\n",
        "    N = len(y_true) - P\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        TP = np.sum((y_scores >= thresh) & (y_true == 1))\n",
        "        FP = np.sum((y_scores >= thresh) & (y_true == 0))\n",
        "        TPR = TP / P if P != 0 else 0\n",
        "        FPR = FP / N if N != 0 else 0\n",
        "        tpr.append(TPR)\n",
        "        fpr.append(FPR)\n",
        "\n",
        "    # Sort FPR and TPR\n",
        "    fpr = np.array(fpr)\n",
        "    tpr = np.array(tpr)\n",
        "    sorted_indices = np.argsort(fpr)\n",
        "    fpr = fpr[sorted_indices]\n",
        "    tpr = tpr[sorted_indices]\n",
        "\n",
        "    # Compute AUC using the trapezoidal rule\n",
        "    auc = np.trapz(tpr, fpr)\n",
        "    return auc\n"
      ],
      "metadata": {
        "id": "RyfC8v9Btyql"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "EsMdEr4DpWjB"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    # TODO: Implement cross-validation\n",
        "    # Compute ROC AUC scores\n",
        "    n_samples = len(y)\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    # Shuffle indices\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Stratify the data\n",
        "    unique_classes = np.unique(y)\n",
        "    folds = [[] for _ in range(n_splits)]\n",
        "    class_indices = {cls: np.where(y == cls)[0] for cls in unique_classes}\n",
        "\n",
        "    # Distribute samples to folds\n",
        "    for cls in unique_classes:\n",
        "        cls_indices = class_indices[cls]\n",
        "        np.random.shuffle(cls_indices)\n",
        "        cls_fold_sizes = np.full(n_splits, len(cls_indices) // n_splits)\n",
        "        cls_fold_sizes[:len(cls_indices) % n_splits] += 1\n",
        "        current = 0\n",
        "        for fold_idx, fold_size in enumerate(cls_fold_sizes):\n",
        "            folds[fold_idx].extend(cls_indices[current:current + fold_size])\n",
        "            current += fold_size\n",
        "\n",
        "    auc_scores = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        test_indices = np.array(folds[i])\n",
        "        train_indices = np.array([idx for fold in folds[:i] + folds[i+1:] for idx in fold])\n",
        "\n",
        "        X_train_cv, X_val_cv = X[train_indices], X[test_indices]\n",
        "        y_train_cv, y_val_cv = y[train_indices], y[test_indices]\n",
        "\n",
        "        # Create a new instance of knn to avoid data leakage\n",
        "        knn_cv = KNN(k=knn.k, distance_metric=knn.distance_metric)\n",
        "        knn_cv.fit(X_train_cv, y_train_cv)\n",
        "\n",
        "        # Predict probabilities\n",
        "        y_pred_prob = knn_cv.predict(X_val_cv)\n",
        "\n",
        "        # Compute ROC AUC score\n",
        "        auc = compute_roc_auc(y_val_cv, y_pred_prob)\n",
        "        auc_scores.append(auc)\n",
        "\n",
        "    return auc_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNmiwOL1pWjB",
        "outputId": "fe27f45a-c20d-4b19-a1e2-0cbc7e6abab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-113-26c4c13eb6bd>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[col].fillna(data[col].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of np: <class 'module'>\n",
            "Cross-validation scores: [0.8546740960033251, 0.8720108205714727, 0.8711460045120619, 0.8670431084061185, 0.8780925940483727]\n",
            "Metric: euclidean, k: 3, Mean ROC AUC: 0.842372603382076\n",
            "Metric: euclidean, k: 5, Mean ROC AUC: 0.8715665256018461\n",
            "Metric: euclidean, k: 7, Mean ROC AUC: 0.8801769920105503\n",
            "Metric: euclidean, k: 9, Mean ROC AUC: 0.8871519896910639\n",
            "Metric: euclidean, k: 11, Mean ROC AUC: 0.891472734268105\n",
            "Metric: manhattan, k: 3, Mean ROC AUC: 0.840912733640679\n",
            "Metric: manhattan, k: 5, Mean ROC AUC: 0.8687442170202301\n",
            "Metric: manhattan, k: 7, Mean ROC AUC: 0.8799701314356312\n",
            "Metric: manhattan, k: 9, Mean ROC AUC: 0.8880040269526587\n",
            "Metric: manhattan, k: 11, Mean ROC AUC: 0.8950077220278301\n",
            "Metric: minkowski, k: 3, Mean ROC AUC: 0.8367313747197331\n",
            "Metric: minkowski, k: 5, Mean ROC AUC: 0.8697336130310875\n",
            "Metric: minkowski, k: 7, Mean ROC AUC: 0.8826949067491972\n",
            "Metric: minkowski, k: 9, Mean ROC AUC: 0.8889128265387571\n",
            "Metric: minkowski, k: 11, Mean ROC AUC: 0.8921555994237927\n",
            "\n",
            "Best Metric: manhattan, Best k: 11, Best ROC AUC: 0.8950077220278301\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('sample_data/train.csv', 'sample_data/test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "print(\"Type of np:\", type(np))\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# TODO: hyperparamters tuning\n",
        "best_auc = 0\n",
        "best_k = 0\n",
        "best_metric = ''\n",
        "k_values = [3, 5, 7, 9, 11]\n",
        "distance_metrics = ['euclidean', 'manhattan','minkowski']\n",
        "\n",
        "for metric in distance_metrics:\n",
        "    for k in k_values:\n",
        "        # Create a knn object with current hyperparameters\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        auc_scores = cross_validate(X, y, knn, n_splits=5)\n",
        "        mean_auc = np.mean(auc_scores)\n",
        "        print(f\"Metric: {metric}, k: {k}, Mean ROC AUC: {mean_auc}\")\n",
        "        if mean_auc > best_auc:\n",
        "            best_auc = mean_auc\n",
        "            best_k = k\n",
        "            best_metric = metric\n",
        "\n",
        "print(f\"\\nBest Metric: {best_metric}, Best k: {best_k}, Best ROC AUC: {best_auc}\")\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k= best_k, distance_metric=best_metric)\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('sample_data/test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}